{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b9d1b5c",
   "metadata": {},
   "source": [
    "# EDA_Statistical_Thinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc0bb99",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.13.5)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"/home/rahel/Desktop/ AlphaCare Insurance Solutions/venv/bin/python\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set visual styles for plots\n",
    "sns.set_style('whitegrid')\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Robustly load the provided dataset (current file: data/MachineLearningRating_v3.txt)\n",
    "file_path = 'data/MachineLearningRating_v3.txt'\n",
    "try:\n",
    "    # let pandas sniff the separator if possible\n",
    "    data = pd.read_csv(file_path, sep=None, engine='python', low_memory=False)\n",
    "    print(f\"Data loaded successfully from {file_path}.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading {file_path}: {e}\")\n",
    "    # try an alternative relative path\n",
    "    alt = './data/MachineLearningRating_v3.txt'\n",
    "    try:\n",
    "        data = pd.read_csv(alt, sep=None, engine='python', low_memory=False)\n",
    "        print(f\"Data loaded successfully from {alt}.\")\n",
    "    except Exception as e2:\n",
    "        raise FileNotFoundError(f\"Could not load dataset from {file_path} or {alt}: {e2}\")\n",
    "\n",
    "print(\"\\n--- Initial Data Snapshot ---\")\n",
    "print(data.head())\n",
    "\n",
    "print(\"\\n--- Columns detected ---\")\n",
    "print(list(data.columns))\n",
    "\n",
    "## Section 2: Data Structure and Quality Assessment (Task 1.2)\n",
    "\n",
    "### 2.1 Data Structure (KPI: Data Structure)\n",
    "print(\"\\n--- Data Information (Data Types and Non-Null Counts) ---\")\n",
    "print(data.info())\n",
    "\n",
    "# Detect a date-like column and coerce to datetime into 'TransactionDate'\n",
    "date_cols = [c for c in data.columns if ('date' in c.lower()) or ('transaction' in c.lower()) or ('month' in c.lower())]\n",
    "if date_cols:\n",
    "    date_col = date_cols[0]\n",
    "    data['TransactionDate'] = pd.to_datetime(data[date_col], errors='coerce')\n",
    "    print(f\"\\nParsed date-like column '{date_col}' into 'TransactionDate' (nulls if parsing failed).\")\n",
    "else:\n",
    "    print(\"\\nNo date-like column found; 'TransactionDate' not created.\")\n",
    "\n",
    "### 2.2 Data Quality Assessment (KPI: Missing Values)\n",
    "print(\"\\n--- Missing Value Check ---\")\n",
    "missing_data = data.isnull().sum()\n",
    "missing_data = missing_data[missing_data > 0].sort_values(ascending=False)\n",
    "print(missing_data)\n",
    "\n",
    "### 2.3 Descriptive Statistics (KPI: Variability)\n",
    "print(\"\\n--- Descriptive Statistics for Financial/Numerical Features ---\")\n",
    "# Focus on common financial and numerical columns (pick those that exist)\n",
    "possible_numerical = ['TotalPremium', 'TotalClaims', 'SumInsured', 'CustomValueEstimate', 'Cubiccapacity', 'Kilowatts']\n",
    "numerical_cols = [c for c in possible_numerical if c in data.columns]\n",
    "if numerical_cols:\n",
    "    print(data[numerical_cols].describe())\n",
    "else:\n",
    "    print(\"None of the expected numerical columns were found: \" + str(possible_numerical))\n",
    "\n",
    "# Variability check for TotalPremium and TotalClaims if present\n",
    "if 'TotalPremium' in data.columns and 'TotalClaims' in data.columns:\n",
    "    premium_std = data['TotalPremium'].std()\n",
    "    claims_std = data['TotalClaims'].std()\n",
    "    print(f\"\\nVariability (Standard Deviation):\")\n",
    "    print(f\"TotalPremium: {premium_std:,.2f}\")\n",
    "    print(f\"TotalClaims: {claims_std:,.2f}\")\n",
    "else:\n",
    "    print(\"Cannot compute std for 'TotalPremium'/'TotalClaims' — one or both columns missing.\")\n",
    "\n",
    "\n",
    "## Section 3: Exploratory Data Analysis (EDA) - Initial Insights\n",
    "\n",
    "### 3.1 Overall Loss Ratio Calculation\n",
    "# Loss Ratio = TotalClaims / TotalPremium (summed over the portfolio)\n",
    "if ('TotalPremium' in data.columns) and ('TotalClaims' in data.columns):\n",
    "    total_premium = data['TotalPremium'].sum(skipna=True)\n",
    "    total_claims = data['TotalClaims'].sum(skipna=True)\n",
    "    if total_premium > 0:\n",
    "        overall_loss_ratio = total_claims / total_premium\n",
    "        print(f\"\\n--- Overall Portfolio Loss Ratio ---\")\n",
    "        print(f\"Overall Loss Ratio: {overall_loss_ratio:.4f} (or {overall_loss_ratio*100:.2f}%)\")\n",
    "    else:\n",
    "        print(\"TotalPremium sums to zero; cannot compute overall loss ratio.\")\n",
    "else:\n",
    "    print(\"Columns 'TotalPremium' and/or 'TotalClaims' missing; skipping loss ratio calculation.\")\n",
    "\n",
    "# --- Continue your EDA here with the required Univariate, Bivariate, and Multivariate analysis ---\n",
    "# E.g., Calculating Loss Ratio by Province, plotting histograms, etc.\n",
    "\n",
    "# You can start calculating loss ratio by Province here if columns exist:\n",
    "if ('Province' in data.columns) and ('TotalPremium' in data.columns) and ('TotalClaims' in data.columns):\n",
    "    print(\"\\n--- Loss Ratio by Province ---\")\n",
    "    province_risk = data.groupby('Province').agg(\"\n",
    "    TotalPremium=('TotalPremium', 'sum'),\",\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    "\n",
    "# Create 'HadClaim' flag from 'TotalClaims' if not present\n",
    "if 'HadClaim' not in data.columns:\n",
    "    if 'TotalClaims' in data.columns:\n",
    "        data['HadClaim'] = (data['TotalClaims'] > 0).astype(int)\n",
    "        print(\"Created 'HadClaim' from 'TotalClaims'.\")\n",
    "    else:\n",
    "        data['HadClaim'] = np.nan\n",
    "        print(\"'HadClaim' not created — 'TotalClaims' missing.\")\n",
    "\n",
    "# You would then visualize this as one of your required plots.\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d77cbf",
   "metadata": {},
   "source": [
    "# Temporal Trends Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b7d586",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aggregate data by month\n",
    "monthly_data = data.groupby(pd.Grouper(key='TransactionDate', freq='M')).agg(\n",
    "    TotalMonthlyClaims=('TotalClaims', 'sum'),\n",
    "    PolicyCount=('PolicyID', 'count'),\n",
    "    ClaimCount=('HadClaim', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "monthly_data['ClaimFrequency'] = monthly_data['ClaimCount'] / monthly_data['PolicyCount']\n",
    "# Calculate Claim Severity: Total Claims / Number of Claims\n",
    "monthly_data['ClaimSeverity'] = monthly_data['TotalMonthlyClaims'] / monthly_data['ClaimCount']\n",
    "\n",
    "# Plotting the trend (Plot 1 of 3: Creative Plot)\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.lineplot(x='TransactionDate', y='ClaimSeverity', data=monthly_data, label='Claim Severity (Rand)')\n",
    "sns.lineplot(x='TransactionDate', y='ClaimFrequency', data=monthly_data, label='Claim Frequency (Proportion)', color='red')\n",
    "plt.title('Temporal Trend: Claim Severity and Claim Frequency (Feb 2014 - Aug 2015)')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Transaction Month')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e332b",
   "metadata": {},
   "source": [
    "# Outlier Detection (Box Plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7e581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up figure for box plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Box Plot 1: TotalClaims (Zoomed in for clarity)\n",
    "sns.boxplot(y=data['TotalClaims'], ax=axes[0])\n",
    "axes[0].set_title('Box Plot of TotalClaims (Zoomed)')\n",
    "# Limit y-axis to focus on the bulk of the data and show extreme outliers as dots\n",
    "axes[0].set_ylim(0, data['TotalClaims'].quantile(0.99)) \n",
    "axes[0].set_ylabel('Total Claims Amount (Rand)')\n",
    "\n",
    "# Box Plot 2: CustomValueEstimate (Zoomed in for clarity)\n",
    "sns.boxplot(y=data['CustomValueEstimate'], ax=axes[1])\n",
    "axes[1].set_title('Box Plot of CustomValueEstimate (Zoomed)')\n",
    "axes[1].set_ylim(0, data['CustomValueEstimate'].quantile(0.99))\n",
    "axes[1].set_ylabel('Custom Value Estimate (Rand)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f00704c",
   "metadata": {},
   "source": [
    "# Creative Plot 2: Geographical Risk Comparison (Loss Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b3f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Filter for provinces with substantial volume (e.g., more than 1000 policies)\n",
    "province_volume = data['Province'].value_counts()\n",
    "provinces_to_plot = province_volume[province_volume >= 1000].index\n",
    "\n",
    "province_risk_plot = calculate_loss_ratio(data[data['Province'].isin(provinces_to_plot)], 'Province')\n",
    "province_risk_plot = province_risk_plot.sort_values(by='LossRatio', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.barplot(x=province_risk_plot.index, y=province_risk_plot['LossRatio'] * 100, palette='viridis')\n",
    "plt.title('Loss Ratio (%) by Province (Actionable Insight)')\n",
    "plt.xlabel('Province')\n",
    "plt.ylabel('Loss Ratio (%)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eef76a",
   "metadata": {},
   "source": [
    "# Creative Plot 3: Risk by Vehicle Make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d93bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_makes = data['Make'].value_counts().head(10).index.tolist()\n",
    "make_risk_plot = data[data['Make'].isin(top_makes)].copy()\n",
    "\n",
    "# Calculate Claim Severity for the top makes\n",
    "make_severity = make_risk_plot[make_risk_plot['HadClaim'] == 1].groupby('Make')['TotalClaims'].mean().reset_index()\n",
    "make_severity = make_severity.sort_values(by='TotalClaims', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.barplot(x='Make', y='TotalClaims', data=make_severity, palette='inferno')\n",
    "plt.title('Average Claim Severity (Rand) for Top 10 Vehicle Makes')\n",
    "plt.xlabel('Vehicle Make')\n",
    "plt.ylabel('Average Claim Amount (Rand)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
